<!DOCTYPE html>
<html>

<head>
    <title>MobileSAM in the Browser</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.14.0/ort.wasm.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <style>
    .mobilesam-content body {
        font-family: Arial, sans-serif;
        background-color: #f2f2f2;
        margin: 0;
        padding: 20px;
    }
    .mobilesam-content h1 {
        color: #333;
        text-align: center;
    }
    .mobilesam-content .upload-container label {
        display: block;
        margin-bottom: 10px;
        text-align: center;
    }
    .mobilesam-content #status {
        display: block;
        margin-bottom: 20px;
        font-weight: bold;
    }
    .mobilesam-content #canvas-container, .row, .col-md-6 {
        display: flex;
        justify-content: center;
        align-items: center;
        width: 100%; /* Forces all containers to expand to full width */
        padding: 0;  /* Removes padding to allow full width utilization */
        margin: 0;   /* Removes margins to allow full width utilization */
        text-align: center;
    }
    .mobilesam-content canvas {
        border: 1px solid #ccc;
        display: block;
        width: 100%; /* Ensure canvas takes full width */
        height: auto; /* Maintain aspect ratio */
        margin: 0; /* Remove margins to ensure full width */
    }
    .mobilesam-content button {
        display: block;
        width: 100%; /* Ensure buttons take full width */
        margin: 0; /* Remove any default margin */
        padding: 10px; /* Adds padding for better usability */
        font-size: 16px; /* Increases font size for better readability */
    }
    #loading-gif {
        width: 20%;  /* Makes the image take the full width of its container */
        max-width: 200px; /* Adjusts the maximum width to match the button size */
        height: auto; /* Keeps the image aspect ratio intact */
        display: none; /* Keeps the GIF hidden initially */
    }
</style>



    <link rel="preload" href="/static/models/mobilesam.decoder.quant.onnx" as="fetch" crossorigin="anonymous">
    <link rel="preload" href="/static/models/mobilesam.encoder.onnx" as="fetch" crossorigin="anonymous">
</head>

<body>
<div class="mobilesam-content">
    <div id="main" class="container">
        <div class="row justify-content-center">
            <div class="col-md-6 text-center">
                <label for="file-in" class="btn btn-primary btn-block mt-3">Upload Image</label>
                <input title="Image from File" type="file" id="file-in" name="file-in" style="display: none;">
            </div>
        </div>
        <div id="canvas-container" class="row mt-3 justify-content-center">
            <div class="col-md-6 text-center">
                <div style="display: none;">
                    <img id="original-image" src="#" />
                </div>
                <canvas id="canvas"></canvas>
            </div>
        </div>
        <div class="row mt-3 justify-content-center">
            <div class="col-md-6 text-center">
                <span id="status">No image uploaded</span>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-md-6 text-center">
                <button id="make-prediction" class="btn btn-success btn-block mt-3" style="display:none;">Make Prediction</button>
            </div>
        </div>

        <div class="row justify-content-center">
            <div class="col-md-6 text-center">
                <!-- Loading GIF, hidden by default, shown during loading -->
                <img id="loading-gif" src="/static/animation.gif" alt="Loading..." style="display: none;">
            </div>
        </div>

        <div class="row mt-3 justify-content-center">
            <div class="col-md-6 text-center">
                <div id="prediction-result"></div>
            </div>
        </div>
    </div>
</div>


<script>
    const dimension = 1024;
    let canvas = document.getElementById('canvas');
    let image_embeddings;
    let imageImageData;

    async function handleClick(event) {
        const canvasRect = canvas.getBoundingClientRect();
        const scaleX = canvas.width / canvasRect.width;   // ratio of actual width to displayed width
        const scaleY = canvas.height / canvasRect.height; // ratio of actual height to displayed height

        // Adjust mouse event coordinates to canvas resolution
        const x = (event.clientX - canvasRect.left) * scaleX;
        const y = (event.clientY - canvasRect.top) * scaleY;

        console.log('Adjusted Click Position:', x, y);
        document.getElementById("status").textContent = `Clicked on (${Math.round(x)}, ${Math.round(y)}). Generating mask...`;

        let context = canvas.getContext('2d');
        context.clearRect(0, 0, canvas.width, canvas.height);
        context.putImageData(imageImageData, 0, 0);
        context.fillStyle = 'green';
        context.fillRect(x, y, 10, 10); // Draw a box at the click location
        const pointCoords = new ort.Tensor(new Float32Array([x, y, 0, 0]), [1, 2, 2]);
        const pointLabels = new ort.Tensor(new Float32Array([0, -1]), [1, 2]);
        const maskInput = new ort.Tensor(new Float32Array(256 * 256), [1, 1, 256, 256]);
        const hasMask = new ort.Tensor(new Float32Array([0]), [1,]);
        const origianlImageSize = new ort.Tensor(new Float32Array([684, 1024]), [2,]);

        ort.env.wasm.numThreads = 1;
        const decodingSession = await ort.InferenceSession.create('/static/models/mobilesam.decoder.quant.onnx');
        console.log("Decoder session", decodingSession);
        const decodingFeeds = {
            "image_embeddings": image_embeddings,
            "point_coords": pointCoords,
            "point_labels": pointLabels,
            "mask_input": maskInput,
            "has_mask_input": hasMask,
            "orig_im_size": origianlImageSize
        }

        start = Date.now();
        try {
            results = await decodingSession.run(decodingFeeds);
            console.log("Generated mask:", results);
            const mask = results.masks;
            const maskImageData = mask.toImageData();
            context.globalAlpha = 0.5;
            // convert image data to image bitmap
            let imageBitmap = await createImageBitmap(maskImageData);
            context.drawImage(imageBitmap, 0, 0);
            document.getElementById("make-prediction").style.display = "block"; // Show the prediction button

            // Save the masked image
            const maskedImageDataUrl = canvas.toDataURL('image/png');
            saveMaskedImage(maskedImageDataUrl);

        } catch (error) {
            console.log(`caught error: ${error}`)
        }
        end = Date.now();
        console.log(`generating masks took ${(end - start) / 1000} seconds`);
        document.getElementById("status").textContent = `Mask generated. Click on the image to generate new mask.`;
    }

    async function handleImage(img) {
        document.getElementById("status").textContent = `Uploaded image is ${img.width}x${img.height}px. Loading the encoder model (~28 MB).`;
        console.log(`Uploaded image of size ${img.width}x${img.height}`);
        const scaleX = dimension / img.width;
        const scaleY = dimension / img.height;

        ort.env.wasm.numThreads = 1;
        const resizedTensor = await ort.Tensor.fromImage(img, options = { resizedWidth: 1024, resizedHeight: 684 });
        const resizeImage = resizedTensor.toImageData();
        let imageDataTensor = await ort.Tensor.fromImage(resizeImage);
        imageImageData = imageDataTensor.toImageData();
        console.log("image data tensor:", imageDataTensor);

        canvas.width = imageImageData.width;
        canvas.height = imageImageData.height;
        let context = canvas.getContext('2d');
        context.putImageData(imageImageData, 0, 0);

        let tf_tensor = tf.tensor(imageDataTensor.data, imageDataTensor.dims);
        tf_tensor = tf_tensor.reshape([3, 684, 1024]);
        tf_tensor = tf_tensor.transpose([1, 2, 0]).mul(255);
        imageDataTensor = new ort.Tensor(tf_tensor.dataSync(), tf_tensor.shape);

        ort.env.wasm.numThreads = 1;
        const session = await ort.InferenceSession.create('/static/models/mobilesam.encoder.onnx');
        console.log("Encoder Session", session);
        const feeds = { "input_image": imageDataTensor };
        let start = Date.now();
        let results;
        try {
            results = await session.run(feeds);
            console.log("Encoding result:", results);
            image_embeddings = results.image_embeddings;
        } catch (error) {
            console.log(`caught error: ${error}`)
            document.getElementById("status").textContent = `Error: ${error}`;
        }
        let end = Date.now();
        let time_taken = (end - start) / 1000;
        console.log(`Computing image embedding took ${time_taken} seconds`);
        document.getElementById("status").textContent = `Embedding generated in ${time_taken} seconds. Click on the image to generate a mask.`;

        canvas.addEventListener('click', handleClick);
    }

    function loadImage(fileReader) {
        let img = document.getElementById("original-image");
        img.onload = () => handleImage(img);
        img.src = fileReader.result;
    }

    async function makePrediction() {
        // Call the Python function in app.py to make the prediction
        const response = await fetch('/make_prediction', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({})
        });

        const data = await response.json();
        console.log(data);
        document.getElementById("prediction-result").innerText = JSON.stringify(data, null, 2);

    }

    async function saveMaskedImage(maskedImageDataUrl) {
        // Call the Python function in app.py to save the masked image
        const response = await fetch('/save_masked_image', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ masked_image_data_url: maskedImageDataUrl })
        });

        const result = await response.json();
        console.log(result);
    }

    async function main() {
        let img = document.getElementById("original-image");
        document.getElementById("file-in").onchange = function (evt) {
            let target = evt.target || window.event.src, files = target.files;
            if (FileReader && files && files.length) {
                let fileReader = new FileReader();
                fileReader.onload = () => loadImage(fileReader);
                fileReader.readAsDataURL(files[0]);
            }
        };

        // Add event listener for the "Make Prediction" button
        document.getElementById("make-prediction").addEventListener("click", makePrediction);
    }





     async function makePrediction() {
        document.getElementById("make-prediction").style.display = 'none'; // Hide the prediction button
        document.getElementById("loading-gif").style.display = 'block'; // Show the loading GIF

        // Simulate a delay for the prediction or await the prediction process
        setTimeout(async () => {
            const response = await fetch('/make_prediction', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({})
            });

            const data = await response.json();
            document.getElementById("prediction-result").innerText = JSON.stringify(data, null, 2);

            document.getElementById("loading-gif").style.display = 'none'; // Hide the loading GIF
            document.getElementById("make-prediction").style.display = 'block'; // Show the prediction button again
            document.getElementById("prediction-result").style.display = 'block'; // Show the prediction result
        }, 2000); // Adjust the timeout to match the actual prediction time if needed
    }



    main();

</script>
</body>

</html>

